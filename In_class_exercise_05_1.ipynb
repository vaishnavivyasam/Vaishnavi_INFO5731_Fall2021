{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_05-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishnavivyasam/Vaishnavi_INFO5731_Fall2021/blob/main/In_class_exercise_05_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6B0aD3EZx2C"
      },
      "source": [
        "# **The fifth in-class-exercise (40 points in total, 11/11/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZryeQ3HZx2q"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "fsPP9bOCZx2w",
        "outputId": "b289e835-456f-4de5-818b-f19a28d59a00"
      },
      "source": [
        "import pandas as pd \n",
        "import re \n",
        "import nltk \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "  \n",
        "dataset = pd.read_csv(\"stsa-train.txt\", sep='delimiter', header=None) \n",
        "#dataset              \n",
        "dataset = pd.DataFrame(dataset) \n",
        "dataset.columns = [\"Text\"] \n",
        "dataset['Reviews'] = dataset['Text'].str.split(' ').str[0]\n",
        "dataset['Text'] = dataset['Text'].str.split(n=1).str[1]\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>painful , horrifying and oppressively tragic ,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6916</th>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6917</th>\n",
              "      <td>the script covers huge , heavy topics in a bla...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6918</th>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6919</th>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6920 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text Reviews\n",
              "0     a stirring , funny and finally transporting re...       1\n",
              "1     apparently reassembled from the cutting-room f...       0\n",
              "2     they presume their audience wo n't sit still f...       0\n",
              "3     this is a visually stunning rumination on love...       1\n",
              "4     jonathan parker 's bartleby should have been t...       1\n",
              "...                                                 ...     ...\n",
              "6915  painful , horrifying and oppressively tragic ,...       1\n",
              "6916  take care is nicely performed by a quintet of ...       0\n",
              "6917  the script covers huge , heavy topics in a bla...       0\n",
              "6918  a seriously bad film with seriously warped log...       0\n",
              "6919  a deliciously nonsensical comedy about a city ...       1\n",
              "\n",
              "[6920 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "SRfSBXg6bwjU",
        "outputId": "7c61bb08-f45f-400f-c68e-fcdf2803e1cd"
      },
      "source": [
        "dataset_test = pd.read_csv(\"stsa-test.txt\", sep='delimiter', header=None)        \n",
        "dataset_test = pd.DataFrame(dataset_test) \n",
        "dataset_test.columns = [\"Text\"] \n",
        "dataset_test['Reviews'] = dataset_test['Text'].str.split(' ').str[0]\n",
        "#dataset  \n",
        "dataset_test['Text'] = dataset_test['Text'].str.split(n=1).str[1]\n",
        "dataset_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816</th>\n",
              "      <td>an often-deadly boring , strange reading of a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>safe conduct , however ambitious and well-inte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>a film made with as little wit , interest , an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1820</th>\n",
              "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1821 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text Reviews\n",
              "0        no movement , no yuks , not much of anything .       0\n",
              "1     a gob of drivel so sickly sweet , even the eag...       0\n",
              "2     gangs of new york is an unapologetic mess , wh...       0\n",
              "3     we never really feel involved with the story ,...       0\n",
              "4               this is one of polanski 's best films .       1\n",
              "...                                                 ...     ...\n",
              "1816  an often-deadly boring , strange reading of a ...       0\n",
              "1817  the problem with concept films is that if the ...       0\n",
              "1818  safe conduct , however ambitious and well-inte...       0\n",
              "1819  a film made with as little wit , interest , an...       0\n",
              "1820  but here 's the real damn : it is n't funny , ...       0\n",
              "\n",
              "[1821 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGfxwl0Rb0tD",
        "outputId": "be700e3d-23ea-4ef7-cd4a-9d985cb52340"
      },
      "source": [
        "#Cleaning the data, \n",
        "nltk.download('stopwords') \n",
        "  \n",
        "corpus_train = [] \n",
        "corpus_test = []\n",
        "  \n",
        "for i in range(0, 6920): \n",
        "    text = re.sub('[^a-zA-Z]', '', dataset['Text'][i]) \n",
        "    text = text.lower() \n",
        "    text = text.split() \n",
        "    ps = PorterStemmer() \n",
        "    text = ''.join(text) \n",
        "    corpus_train.append(text)\n",
        "\n",
        "for i in range(0, 1821): \n",
        "    text = re.sub('[^a-zA-Z]', '', dataset_test['Text'][i]) \n",
        "    text = text.lower() \n",
        "    text = text.split() \n",
        "    ps = PorterStemmer() \n",
        "    text = ''.join(text) \n",
        "    corpus_test.append(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ferw4WEdcBAe",
        "outputId": "c22f663f-c00e-48b0-9e48-83d5b45e5e6a"
      },
      "source": [
        "# creating bag of words model \n",
        "cv = CountVectorizer(max_features = 1500) \n",
        "  \n",
        "X = cv.fit_transform(corpus_train).toarray() \n",
        "y = dataset.iloc[:, 1].values\n",
        "\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1' '0' '0' ... '0' '0' '1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAq54a2bcEDq"
      },
      "source": [
        "# splitting the data set into training set and validation set \n",
        "from sklearn.model_selection import train_test_split \n",
        "  \n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFCCTgdfcG4S"
      },
      "source": [
        "#1.MultinomialNB\n",
        "\n",
        "# fitting naive bayes to the training set \n",
        "import sklearn.metrics as metrics \n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier = MultinomialNB()\n",
        "model = classifier.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdBOMmLOk7TD",
        "outputId": "2f4284be-5ac0-4d06-ecda-27410d35f2a6"
      },
      "source": [
        "#Printing accuracy from test values\n",
        "print('Accuracy %s' % accuracy_score(y_pred,y_test))\n",
        "#Comparing results between predicted and actual values\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.5296242774566474\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.00      0.00       651\n",
            "           1       0.53      1.00      0.69       733\n",
            "\n",
            "    accuracy                           0.53      1384\n",
            "   macro avg       0.51      0.50      0.35      1384\n",
            "weighted avg       0.52      0.53      0.37      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG8L6f_3pxQq",
        "outputId": "2f7fe885-734a-4112-ff95-c7781ac6766c"
      },
      "source": [
        "#For calculating the cross-validation scores\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(classifier, X_test, y_test, cv=10)\n",
        "#Printing the scores\n",
        "print(\"multinomialNB\",scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multinomialNB 0.5296215201751643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXtglyTsdERx",
        "outputId": "55114943-12dd-4d45-8aeb-030cab40f559"
      },
      "source": [
        "#2.SVM\n",
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "model_svm = clf.fit(X_train, y_train)\n",
        "\n",
        "#Printing accuracy for the test values\n",
        "print('Accuracy %s' % accuracy_score(y_pred,y_test))\n",
        "#Comparing results between predicted and actual values\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#For calculating the cross-validation scores\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(clf, X_test, y_test, cv=10)\n",
        "print(\"SVM\",scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.5296242774566474\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.00      0.00       651\n",
            "           1       0.53      1.00      0.69       733\n",
            "\n",
            "    accuracy                           0.53      1384\n",
            "   macro avg       0.51      0.50      0.35      1384\n",
            "weighted avg       0.52      0.53      0.37      1384\n",
            "\n",
            "SVM 0.5123292670211657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfa41urIeEFt"
      },
      "source": [
        "#3.KNN\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_val = scaler.transform(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjSdXK70ejXD",
        "outputId": "1f970273-0b98-4301-8a2a-a9400b91dd29"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_RtHMfdxinU",
        "outputId": "fd2bd763-f051-467e-b0a7-42c10f4e69fe"
      },
      "source": [
        "#Printing accuracy for the test values\n",
        "print('Accuracy %s' % accuracy_score(y_pred,y_test))\n",
        "#Comparing results between predicted and actual values\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#For calculating the cross-validation scores\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(classifier, X_test, y_test, cv=10)\n",
        "print(\"using KNN\",scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.5296242774566474\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.00      0.00       651\n",
            "           1       0.53      1.00      0.69       733\n",
            "\n",
            "    accuracy                           0.53      1384\n",
            "   macro avg       0.51      0.50      0.35      1384\n",
            "weighted avg       0.52      0.53      0.37      1384\n",
            "\n",
            "using KNN 0.5296215201751643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHAZSv5ietId",
        "outputId": "edc5ece8-5b15-4545-f626-bbcf6952f0ee"
      },
      "source": [
        "#4.DECISION TREE\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "import sklearn.metrics as metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "\n",
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "#Printing accuracy for the test values\n",
        "print('Accuracy %s' % accuracy_score(y_pred,y_test))\n",
        "#Comparing results between predicted and actual values\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#For calculating the cross-validation scores\n",
        "scores = cross_val_score(clf, X_test, y_test, cv=10)\n",
        "print(\"using decision trees\",scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.5296242774566474\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.00      0.00       651\n",
            "           1       0.53      1.00      0.69       733\n",
            "\n",
            "    accuracy                           0.53      1384\n",
            "   macro avg       0.51      0.50      0.35      1384\n",
            "weighted avg       0.52      0.53      0.37      1384\n",
            "\n",
            "using decision trees 0.5296215201751643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJQXQTYIhGAC"
      },
      "source": [
        "#RANDOM FOREST\n",
        "\n",
        "#Import Random Forest Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JkY6HtH_CmM",
        "outputId": "ba19a3e8-3546-4cc8-bfd0-00abcb3be758"
      },
      "source": [
        "#Printing accuracy for the test values\n",
        "print('Accuracy %s' % accuracy_score(y_pred,y_test))\n",
        "#Comparing results between predicted and actual values\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#For calculating the cross-validation scores\n",
        "scores = cross_val_score(clf, X_test, y_test, cv=10)\n",
        "print(\"using random forest\",scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.5296242774566474\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.00      0.00       651\n",
            "           1       0.53      1.00      0.69       733\n",
            "\n",
            "    accuracy                           0.53      1384\n",
            "   macro avg       0.51      0.50      0.35      1384\n",
            "weighted avg       0.52      0.53      0.37      1384\n",
            "\n",
            "using random forest 0.5296215201751643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhIEIlDditEF",
        "outputId": "3b303f77-e768-4b0d-fc38-44435b0ea3be"
      },
      "source": [
        "#XGBoost\n",
        "\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
        "xg_reg.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:42:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=0.3, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=5, min_child_weight=1, missing=None, n_estimators=10,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ3wQZQ2izMf",
        "outputId": "31a1c327-cd3f-4d2b-b3b1-c0689055e7d2"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "print(\"RMSE: %f\" % (rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.499302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLm20yo-Zx24"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K means, \n",
        "DBSCAN,\n",
        "Hierarchical clustering. \n",
        "\n",
        "You can refer to of the codes from  the follwing link below. \n",
        "https://www.kaggle.com/karthik3890/text-clustering "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "EfgKzqkLZx28",
        "outputId": "9b061316-f53c-4249-a5c4-f1bd69dc90f3"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4c4ea62b-ce21-45f3-b187-fe50d5aededb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4c4ea62b-ce21-45f3-b187-fe50d5aededb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Amazon_Unlocked_Mobile.csv to Amazon_Unlocked_Mobile.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "75mRQvJvUiak",
        "outputId": "cb9e8277-3179-4dda-c346-b2dc514f0c03"
      },
      "source": [
        "#Write your code here.\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"Amazon_Unlocked_Mobile.csv\")\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413835</th>\n",
              "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>79.95</td>\n",
              "      <td>5</td>\n",
              "      <td>another great deal great price</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413836</th>\n",
              "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>79.95</td>\n",
              "      <td>3</td>\n",
              "      <td>Ok</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413837</th>\n",
              "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>79.95</td>\n",
              "      <td>5</td>\n",
              "      <td>Passes every drop test onto porcelain tile!</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413838</th>\n",
              "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>79.95</td>\n",
              "      <td>3</td>\n",
              "      <td>I returned it because it did not meet my needs...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413839</th>\n",
              "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>79.95</td>\n",
              "      <td>4</td>\n",
              "      <td>Only downside is that apparently Verizon no lo...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>413840 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Product Name  ... Review Votes\n",
              "0       \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          1.0\n",
              "1       \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "2       \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "3       \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "4       \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "...                                                   ...  ...          ...\n",
              "413835  Samsung Convoy U640 Phone for Verizon Wireless...  ...          0.0\n",
              "413836  Samsung Convoy U640 Phone for Verizon Wireless...  ...          0.0\n",
              "413837  Samsung Convoy U640 Phone for Verizon Wireless...  ...          0.0\n",
              "413838  Samsung Convoy U640 Phone for Verizon Wireless...  ...          0.0\n",
              "413839  Samsung Convoy U640 Phone for Verizon Wireless...  ...          0.0\n",
              "\n",
              "[413840 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggZ837hbUlab",
        "outputId": "f9af7ad3-34db-4bea-f0ab-7711a4ff3ebf"
      },
      "source": [
        "#Data Cleaning\n",
        "df = df[df['Reviews'].notnull()].head(5000)\n",
        "#Removing punctuatiions\n",
        "df['punct'] = df['Reviews'].str.replace('[^\\w\\s].#','')\n",
        "from nltk.corpus import stopwords\n",
        "import nltk \n",
        "nltk.download('wordnet')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "#stopwords removal\n",
        "df['stopwords'] =df['punct'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "#Removing numercis\n",
        "df['numerics']=df['stopwords'].str.replace('[0-9]','')\n",
        "#to lowercase\n",
        "df['lowercase'] =df['numerics'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "#Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "df['stemming']=df['lowercase'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "#Lemmatizing\n",
        "from textblob import Word\n",
        "df['clean'] = df['stemming'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "df['clean']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       i feel lucki found use (phone u & use hard all...\n",
              "1       nice phone, nice grade pantach revue. veri cle...\n",
              "2                                               veri plea\n",
              "3         it work good goe slow sometim good phone i love\n",
              "4       great phone replac lost phone. the thing volum...\n",
              "                              ...                        \n",
              "4995    thi review product may find everywher www worl...\n",
              "4996    the product good structure. i'm still use braz...\n",
              "4997    the iphon fine. it work good condit one major ...\n",
              "4998                           screen crack realli quick.\n",
              "4999    will never buy anyth again. i receiv work. nei...\n",
              "Name: clean, Length: 5000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn7JB8y7IzKs",
        "outputId": "33eca51a-9be7-4aa9-e8f9-ce3bfe37f037"
      },
      "source": [
        "#Vectoring the dataset\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vector = TfidfVectorizer()\n",
        "tfidf = vector.fit_transform(df['clean'].values)\n",
        "tfidf.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 7567)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swpKr5zmI2ch",
        "outputId": "23ef835f-5612-47b5-dd0c-7008ea63e6f9"
      },
      "source": [
        "#K means model \n",
        "from sklearn.cluster import KMeans\n",
        "#Defining the k means model\n",
        "kmodel = KMeans(n_clusters = 5, n_jobs = -1,random_state=99)\n",
        "kmodel.fit(tfidf)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=5, n_init=10, n_jobs=-1, precompute_distances='auto',\n",
              "       random_state=99, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "iM7_URdvI5WJ",
        "outputId": "43a67f91-7a02-46c1-e14b-6cf12a2a06cd"
      },
      "source": [
        "#Creating the labels for model\n",
        "labels_kmeans = kmodel.labels_\n",
        "#Defining the cluster center\n",
        "cluster_center_kmeans=kmodel.cluster_centers_\n",
        "#Getting the features\n",
        "terms = vector.get_feature_names()\n",
        "terms[1:5]\n",
        "#Dataframe with cluster info\n",
        "df['Label'] = kmodel.labels_\n",
        "df"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>punct</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>numerics</th>\n",
              "      <th>lowercase</th>\n",
              "      <th>stemming</th>\n",
              "      <th>clean</th>\n",
              "      <th>Label</th>\n",
              "      <th>AVG Clus Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucky found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucki found use (phone us &amp; use hard al...</td>\n",
              "      <td>i feel lucki found use (phone u &amp; use hard all...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>very pleased</td>\n",
              "      <td>veri pleas</td>\n",
              "      <td>veri plea</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>it works good goes slow sometimes good phone i...</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>great phone replace lost phone. the thing volu...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>5</td>\n",
              "      <td>This review is not for the product as you may ...</td>\n",
              "      <td>64.0</td>\n",
              "      <td>This review is not for the product as you may ...</td>\n",
              "      <td>This review product may find everywhere www wo...</td>\n",
              "      <td>This review product may find everywhere www wo...</td>\n",
              "      <td>this review product may find everywhere www wo...</td>\n",
              "      <td>thi review product may find everywher www worl...</td>\n",
              "      <td>thi review product may find everywher www worl...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>4</td>\n",
              "      <td>The product was in good structure. I'm still n...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The product was in good structure. I'm still n...</td>\n",
              "      <td>The product good structure. I'm still use Braz...</td>\n",
              "      <td>The product good structure. I'm still use Braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>1</td>\n",
              "      <td>The iPhone was fine. It works and is in good c...</td>\n",
              "      <td>157.0</td>\n",
              "      <td>The iPhone was fine. It works and is in good c...</td>\n",
              "      <td>The iPhone fine. It works good condition one m...</td>\n",
              "      <td>The iPhone fine. It works good condition one m...</td>\n",
              "      <td>the iphone fine. it works good condition one m...</td>\n",
              "      <td>the iphon fine. it work good condit one major ...</td>\n",
              "      <td>the iphon fine. it work good condit one major ...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>2</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>screen cracked really quick.</td>\n",
              "      <td>screen crack realli quick.</td>\n",
              "      <td>screen crack realli quick.</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>1</td>\n",
              "      <td>Will never buy anything again. I received it a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Will never buy anything again. I received it a...</td>\n",
              "      <td>Will never buy anything again. I received work...</td>\n",
              "      <td>Will never buy anything again. I received work...</td>\n",
              "      <td>will never buy anything again. i received work...</td>\n",
              "      <td>will never buy anyth again. i receiv work. nei...</td>\n",
              "      <td>will never buy anyth again. i receiv work. nei...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Product Name  ... AVG Clus Label\n",
              "0     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "1     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "2     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "3     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "4     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "...                                                 ...  ...            ...\n",
              "4995     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              5\n",
              "4996     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              4\n",
              "4997     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              3\n",
              "4998     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              2\n",
              "4999     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              1\n",
              "\n",
              "[5000 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm9cZ1YPI7i7",
        "outputId": "a00bba68-d133-49ce-e921-b0c1fea34be1"
      },
      "source": [
        "#Counting the clusters in each point provided\n",
        "df.groupby(['Label'])['clean'].count()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "0    4211\n",
              "1     259\n",
              "2     198\n",
              "3     213\n",
              "4     119\n",
              "Name: clean, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIPpxC35I_5h",
        "outputId": "83c29dfb-731c-44a5-c403-283200bd390a"
      },
      "source": [
        "#Finding the top terms per Clusters\n",
        "print(\"Top terms per cluster:\")\n",
        "#Defing the centroid model\n",
        "centroids = kmodel.cluster_centers_.argsort()[:, ::-1]\n",
        "#Creating the loop for finding the top words\n",
        "for i in range(5):\n",
        "    print(\"Cluster %d:\" % i, end='')\n",
        "    for ind in centroids[i, :5]:\n",
        "        print(' %s' % terms[ind], end='')\n",
        "        print()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top terms per cluster:\n",
            "Cluster 0: phone\n",
            " it\n",
            " work\n",
            " the\n",
            " good\n",
            "Cluster 1: great\n",
            " work\n",
            " phone\n",
            " product\n",
            " price\n",
            "Cluster 2: good\n",
            " veri\n",
            " phone\n",
            " it\n",
            " product\n",
            "Cluster 3: love\n",
            " it\n",
            " phone\n",
            " great\n",
            " daughter\n",
            "Cluster 4: excel\n",
            " product\n",
            " recommend\n",
            " seller\n",
            " phone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwbf4pPbcHw9"
      },
      "source": [
        "#DBscan Clustering\n",
        "from sklearn.cluster import DBSCAN\n",
        "points = 2 * 100\n",
        "def lower_b(nums, targ): \n",
        "    l, r = 0, len(nums) - 1\n",
        "    while l <= r: \n",
        "        mid = int(l + (r - l) / 2)\n",
        "        if nums[mid] >= targ:\n",
        "            r = mid - 1\n",
        "        else:\n",
        "            l = mid + 1\n",
        "    return l"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5bxaY-dpA8D"
      },
      "source": [
        "def com_200th_near_tneigh(x, data): \n",
        "    dists = []\n",
        "    for val in data:\n",
        "        dist = np.sum((x - val) **2 ) \n",
        "        if(len(dists) == 200 and dists[199] > dist): \n",
        "            l = int(lower_b(dists, dist)) \n",
        "            if l < 200 and l >= 0 and dists[l] > dist:\n",
        "                dists[l] = dist\n",
        "        else:\n",
        "            dists.append(dist)\n",
        "            dists.sort()\n",
        "    \n",
        "    return dists[199]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUu4_imwo1lk",
        "outputId": "5c94281c-2c15-4d62-dc4e-ddb9b519b74c"
      },
      "source": [
        "import numpy as np\n",
        "sent_vectors = []; \n",
        "for sent in df['Reviews']: \n",
        "    sent_vec = np.zeros(100) \n",
        "    cnt_words =0; \n",
        "    for word in sent: \n",
        "        try:\n",
        "            vec = w2v_model.wv[word]\n",
        "            sent_vec += vec\n",
        "            cnt_words += 1\n",
        "        except:\n",
        "            pass\n",
        "    sent_vec /= cnt_words\n",
        "    sent_vectors.append(sent_vec)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
            "  del sys.path[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDJEPR4io4TS",
        "outputId": "d783c710-73f2-4a4f-c968-a811f42f9b84"
      },
      "source": [
        "sent_vectors = np.array(sent_vectors)\n",
        "sent_vectors = np.nan_to_num(sent_vectors)\n",
        "sent_vectors.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "BDqLqhDxo7Qu",
        "outputId": "defaa51e-58b6-4e66-a66b-ff1fd2405b69"
      },
      "source": [
        "points = 2 * 100\n",
        "model = DBSCAN(eps = 1, min_samples = points, n_jobs=-1)\n",
        "model.fit(sent_vectors)\n",
        "df['AVG Clus Label'] = model.labels_\n",
        "df"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>punct</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>numerics</th>\n",
              "      <th>lowercase</th>\n",
              "      <th>stemming</th>\n",
              "      <th>clean</th>\n",
              "      <th>Label</th>\n",
              "      <th>AVG Clus Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucky found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucki found use (phone us &amp; use hard al...</td>\n",
              "      <td>i feel lucki found use (phone u &amp; use hard all...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>very pleased</td>\n",
              "      <td>veri pleas</td>\n",
              "      <td>veri plea</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>it works good goes slow sometimes good phone i...</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>great phone replace lost phone. the thing volu...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>5</td>\n",
              "      <td>This review is not for the product as you may ...</td>\n",
              "      <td>64.0</td>\n",
              "      <td>This review is not for the product as you may ...</td>\n",
              "      <td>This review product may find everywhere www wo...</td>\n",
              "      <td>This review product may find everywhere www wo...</td>\n",
              "      <td>this review product may find everywhere www wo...</td>\n",
              "      <td>thi review product may find everywher www worl...</td>\n",
              "      <td>thi review product may find everywher www worl...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>4</td>\n",
              "      <td>The product was in good structure. I'm still n...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The product was in good structure. I'm still n...</td>\n",
              "      <td>The product good structure. I'm still use Braz...</td>\n",
              "      <td>The product good structure. I'm still use Braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>1</td>\n",
              "      <td>The iPhone was fine. It works and is in good c...</td>\n",
              "      <td>157.0</td>\n",
              "      <td>The iPhone was fine. It works and is in good c...</td>\n",
              "      <td>The iPhone fine. It works good condition one m...</td>\n",
              "      <td>The iPhone fine. It works good condition one m...</td>\n",
              "      <td>the iphone fine. it works good condition one m...</td>\n",
              "      <td>the iphon fine. it work good condit one major ...</td>\n",
              "      <td>the iphon fine. it work good condit one major ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>2</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>screen cracked really quick.</td>\n",
              "      <td>screen crack realli quick.</td>\n",
              "      <td>screen crack realli quick.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>1</td>\n",
              "      <td>Will never buy anything again. I received it a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Will never buy anything again. I received it a...</td>\n",
              "      <td>Will never buy anything again. I received work...</td>\n",
              "      <td>Will never buy anything again. I received work...</td>\n",
              "      <td>will never buy anything again. i received work...</td>\n",
              "      <td>will never buy anyth again. i receiv work. nei...</td>\n",
              "      <td>will never buy anyth again. i receiv work. nei...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Product Name  ... AVG Clus Label\n",
              "0     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "1     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "2     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "3     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "4     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "...                                                 ...  ...            ...\n",
              "4995     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "4996     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "4997     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "4998     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "4999     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "\n",
              "[5000 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLswIzn5Gitl"
      },
      "source": [
        "\n",
        "#Applying Hierarchical clustering Model\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "#Defining the model\n",
        "cluster = AgglomerativeClustering(n_clusters=7, affinity='euclidean', linkage='ward')  \n",
        "Agg=cluster.fit_predict(sent_vectors)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "Sam7RCweNAAz",
        "outputId": "e15f5556-a4f7-465b-8dda-41bf66e4c9fb"
      },
      "source": [
        "# Giving Labels/assigning a cluster to each point/text \n",
        "aggdfa = df\n",
        "aggdfa['AVG Clus Label'] = cluster.labels_\n",
        "aggdfa.head(2)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>punct</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>numerics</th>\n",
              "      <th>lowercase</th>\n",
              "      <th>stemming</th>\n",
              "      <th>clean</th>\n",
              "      <th>Label</th>\n",
              "      <th>AVG Clus Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucky found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucki found use (phone us &amp; use hard al...</td>\n",
              "      <td>i feel lucki found use (phone u &amp; use hard all...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Product Name  ... AVG Clus Label\n",
              "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m7Hqa_pGq03",
        "outputId": "95b3aea1-8cc8-4fb2-fb28-a17391e4a9cc"
      },
      "source": [
        "aggdfa.groupby(['Label'])['clean'].count()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "0    4211\n",
              "1     259\n",
              "2     198\n",
              "3     213\n",
              "4     119\n",
              "Name: clean, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tBTYlrEL4t0",
        "outputId": "4203c2b4-7f7b-45e5-8582-b5431e4a656c"
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"2 reviews of assigned to cluster \", i)\n",
        "    print(\"-\" * 70)\n",
        "    print(aggdfa.iloc[aggdfa.groupby(['Label']).groups[i][0]]['clean'])\n",
        "    print('\\n')\n",
        "    print(aggdfa.iloc[aggdfa.groupby(['Label']).groups[i][1]]['clean'])\n",
        "    print('\\n')\n",
        "    print(\"_\" * 70)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 reviews of assigned to cluster  0\n",
            "----------------------------------------------------------------------\n",
            "i feel lucki found use (phone u & use hard all), phone line someon upgrad sold one. my son like old one final fell apart .+ year want upgrade!! thank seller, realli appreci & honesti re: said use phone.i recommend seller highli & would again!!\n",
            "\n",
            "\n",
            "nice phone, nice grade pantach revue. veri clean set easi set up. never android phone fantast say least. perfect size surf social media. great phone samsung\n",
            "\n",
            "\n",
            "______________________________________________________________________\n",
            "2 reviews of assigned to cluster  1\n",
            "----------------------------------------------------------------------\n",
            "phone good littl slow phone old great phone temporari right now. thank great deal\n",
            "\n",
            "\n",
            "phone work great. no problem\n",
            "\n",
            "\n",
            "______________________________________________________________________\n",
            "2 reviews of assigned to cluster  2\n",
            "----------------------------------------------------------------------\n",
            "it work good goe slow sometim good phone i love\n",
            "\n",
            "\n",
            "good condit work good\n",
            "\n",
            "\n",
            "______________________________________________________________________\n",
            "2 reviews of assigned to cluster  3\n",
            "----------------------------------------------------------------------\n",
            "i like phone i bought mom love\n",
            "\n",
            "\n",
            "i love it!\n",
            "\n",
            "\n",
            "______________________________________________________________________\n",
            "2 reviews of assigned to cluster  4\n",
            "----------------------------------------------------------------------\n",
            "excel product perfect condit\n",
            "\n",
            "\n",
            "excel\n",
            "\n",
            "\n",
            "______________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxdLwk5IZx3H"
      },
      "source": [
        "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfdGNrbNPIJw"
      },
      "source": [
        "In K-means clustering, optimal number of clusters are found with the help of elbow method, \n",
        "where as in DBSCAN no.of clusters need not be specified.\n",
        "K means clustering is easier, when compared to DBSCAN model.DBSCAN is used when \n",
        "the dataset has many outliers. DBSCAN require variables like Minimum points etc. \n",
        "Coming to Hierarchical model, it creates a noise which does not work effectievly when working with a huge a dataset.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}